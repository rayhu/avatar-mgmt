import { ref, Ref } from 'vue';

export interface RecordingState {
  isRecording: Ref<boolean>;
  mediaRecorder: Ref<MediaRecorder | null>;
  recordedChunks: Ref<Blob[]>;
  recordedVideoUrl: Ref<string>;
  startRecording: (
    modelViewer: any, 
    audioPlayer: HTMLAudioElement | null, 
    audioUrl: string, 
    startTimelineAnimation: (audio: HTMLAudioElement) => void, 
    syncVisemeWithAudio: (audio: HTMLAudioElement) => void
  ) => Promise<void>;
  stopRecording: () => void;
  resetRecordingState: () => void;
  checkRecordingState: () => void;
  downloadVideo: () => void;
}

export function useRecording(): RecordingState {
  const isRecording = ref(false);
  const mediaRecorder = ref<MediaRecorder | null>(null);
  const recordedChunks = ref<Blob[]>([]);
  const recordedVideoUrl = ref<string>('');
  
  // ä¿å­˜éŸ³é¢‘ä¸Šä¸‹æ–‡å’Œæºï¼Œä»¥é¿å…é‡å¤åˆ›å»º
  let currentAudioContext: AudioContext | null = null;
  let currentAudioSource: MediaElementAudioSourceNode | null = null;
  let connectedAudioElement: HTMLAudioElement | null = null;
  
  // ä¿å­˜å½“å‰å½•åˆ¶æ ¼å¼ä¿¡æ¯
  let currentFileExtension = 'webm'; // é»˜è®¤æ‰©å±•å

  // å¼€å§‹å½•åˆ¶
  async function startRecording(
    modelViewer: any, 
    audioPlayer: HTMLAudioElement | null, 
    audioUrl: string, 
    startTimelineAnimation: (audio: HTMLAudioElement) => void, 
    syncVisemeWithAudio: (audio: HTMLAudioElement) => void
  ) {
    if (!modelViewer) {
      throw new Error('Model viewer not available');
    }

    if (!audioUrl) {
      throw new Error('Audio not available');
    }

    // å¦‚æœå·²ç»åœ¨å½•åˆ¶ï¼Œå…ˆåœæ­¢
    if (isRecording.value) {
      console.log('âš ï¸ Already recording, stopping first...');
      stopRecording();
      // ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†å¼€å§‹æ–°çš„å½•åˆ¶
      setTimeout(() => {
        startRecording(modelViewer, audioPlayer, audioUrl, startTimelineAnimation, syncVisemeWithAudio);
      }, 100);
      return;
    }

    console.log('ğŸ¬ Starting recording with animation sync...');

    try {
      // æ¸…ç†ä¹‹å‰çš„å½•åˆ¶çŠ¶æ€
      if (mediaRecorder.value) {
        mediaRecorder.value.stop();
        mediaRecorder.value = null;
      }
      recordedChunks.value = [];
      
      // è·å–æ¨¡å‹é¢„è§ˆåŒºåŸŸçš„è§†é¢‘æµ
      const videoStream = modelViewer.getVideoStream();
      if (!videoStream) {
        throw new Error('Failed to get video stream');
      }
      
      console.log('ğŸ“¹ Video stream obtained:', {
        videoTracks: videoStream.getVideoTracks().length,
        videoTrackInfo: videoStream.getVideoTracks().map((track: MediaStreamTrack) => ({
          kind: track.kind,
          enabled: track.enabled,
          readyState: track.readyState
        }))
      });

      // è·å–éŸ³é¢‘å…ƒç´ 
      const audioElement = audioPlayer;
      if (!audioElement) {
        throw new Error('Audio element not found');
      }

      // åˆ›å»ºæˆ–é‡ç”¨éŸ³é¢‘ä¸Šä¸‹æ–‡
      let audioContext: AudioContext;
      let audioSource: MediaElementAudioSourceNode;
      
      // å¦‚æœå·²ç»æœ‰è¿æ¥åˆ°åŒä¸€ä¸ªéŸ³é¢‘å…ƒç´ çš„ä¸Šä¸‹æ–‡ï¼Œé‡ç”¨å®ƒ
      if (currentAudioContext && currentAudioSource && connectedAudioElement === audioElement) {
        console.log('ğŸ”„ Reusing existing audio context and source');
        audioContext = currentAudioContext;
        audioSource = currentAudioSource;
      } else {
        // æ¸…ç†ä¹‹å‰çš„è¿æ¥
        if (currentAudioContext && currentAudioSource) {
          console.log('ğŸ§¹ Cleaning up previous audio context');
          try {
            currentAudioSource.disconnect();
            currentAudioContext.close();
          } catch (error) {
            console.warn('âš ï¸ Error cleaning up audio context:', error);
          }
        }
        
        // åˆ›å»ºæ–°çš„éŸ³é¢‘ä¸Šä¸‹æ–‡å’Œæº
        console.log('ğŸµ Creating new audio context for element');
        audioContext = new AudioContext();
        audioSource = audioContext.createMediaElementSource(audioElement);
        
        // ä¿å­˜å½“å‰è¿æ¥
        currentAudioContext = audioContext;
        currentAudioSource = audioSource;
        connectedAudioElement = audioElement;
      }
      
      const audioDestination = audioContext.createMediaStreamDestination();
      
      // æ–­å¼€ä¹‹å‰çš„è¿æ¥å†é‡æ–°è¿æ¥
      try {
        audioSource.disconnect();
      } catch (error) {
        // å¿½ç•¥æ–­å¼€è¿æ¥çš„é”™è¯¯ï¼Œå¯èƒ½æ²¡æœ‰ä¹‹å‰çš„è¿æ¥
      }
      
      audioSource.connect(audioDestination);
      audioSource.connect(audioContext.destination); // ä¿æŒéŸ³é¢‘å¯å¬

      // åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘æµ
      const combinedStream = new MediaStream([
        ...videoStream.getVideoTracks(),
        ...audioDestination.stream.getAudioTracks(),
      ]);
      
      console.log('ğŸµ Combined stream created:', {
        totalTracks: combinedStream.getTracks().length,
        videoTracks: combinedStream.getVideoTracks().length,
        audioTracks: combinedStream.getAudioTracks().length,
        streamId: combinedStream.id
      });

      // æ£€æŸ¥æ”¯æŒçš„è§†é¢‘æ ¼å¼å¹¶åˆ›å»º MediaRecorder å®ä¾‹
      let mimeType = '';
      let fileExtension = '';
      
      // ä¼˜å…ˆå°è¯• MP4 æ ¼å¼
      if (MediaRecorder.isTypeSupported('video/mp4;codecs=h264,aac')) {
        mimeType = 'video/mp4;codecs=h264,aac';
        fileExtension = 'mp4';
        console.log('âœ… Using MP4 format with H.264 + AAC');
      } else if (MediaRecorder.isTypeSupported('video/mp4;codecs=avc1.42E01E,mp4a.40.2')) {
        mimeType = 'video/mp4;codecs=avc1.42E01E,mp4a.40.2';
        fileExtension = 'mp4';
        console.log('âœ… Using MP4 format with AVC1 + MP4A');
      } else if (MediaRecorder.isTypeSupported('video/webm;codecs=h264,opus')) {
        mimeType = 'video/webm;codecs=h264,opus';
        fileExtension = 'webm';
        console.log('âš ï¸ Using WebM format with H.264 + Opus (MP4 not supported)');
      } else if (MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')) {
        mimeType = 'video/webm;codecs=vp9,opus';
        fileExtension = 'webm';
        console.log('âš ï¸ Using WebM format with VP9 + Opus (fallback)');
      } else {
        // æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
        mimeType = 'video/webm';
        fileExtension = 'webm';
        console.warn('âš ï¸ Using basic WebM format (limited codec support)');
      }
      
      // ä¿å­˜å½“å‰æ–‡ä»¶æ‰©å±•åä»¥ä¾›ä¸‹è½½ä½¿ç”¨
      currentFileExtension = fileExtension;
      
      console.log(`ğŸ¬ Selected format: ${mimeType}`);
      
      mediaRecorder.value = new MediaRecorder(combinedStream, {
        mimeType: mimeType,
        videoBitsPerSecond: 2500000, // 2.5Mbps
      });

      // æ”¶é›†å½•åˆ¶çš„æ•°æ®å—
      mediaRecorder.value.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunks.value.push(event.data);
        }
      };

      // å½•åˆ¶å®Œæˆåçš„å¤„ç†
      mediaRecorder.value.onstop = () => {
        console.log('ğŸ“¹ MediaRecorder stopped, processing data...');
        const blob = new Blob(recordedChunks.value, {
          type: mimeType,
        });
        recordedVideoUrl.value = URL.createObjectURL(blob);
        isRecording.value = false;

        // ä¸ç«‹å³å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œä¿ç•™ä»¥ä¾›é‡ç”¨
        console.log('ğŸµ Keeping audio context for potential reuse');
        
        console.log(`âœ… Recording completed in ${fileExtension.toUpperCase()} format`);
      };

      // å½•åˆ¶é”™è¯¯å¤„ç†
      mediaRecorder.value.onerror = (event) => {
        console.error('âŒ MediaRecorder error:', event);
        isRecording.value = false;
        throw new Error('Recording error occurred');
      };

      // å¼€å§‹å½•åˆ¶
      mediaRecorder.value.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®
      isRecording.value = true;

      // é‡ç½®å¹¶æ’­æ”¾éŸ³é¢‘
      audioElement.currentTime = 0;

      // æ·»åŠ éŸ³é¢‘ç»“æŸäº‹ä»¶ç›‘å¬å™¨
      const handleAudioEnded = () => {
        if (isRecording.value) {
          console.log('ğŸµ Audio ended, stopping recording...');
          stopRecording();
        }
        audioElement.removeEventListener('ended', handleAudioEnded);
      };
      audioElement.addEventListener('ended', handleAudioEnded);

      // æ’­æ”¾éŸ³é¢‘å¹¶åŒæ­¥åŠ¨ç”»
      await audioElement.play();
      console.log('ğŸµ Recording audio started, syncing animation...');
      
      // ç¡®ä¿åŠ¨ç”»ä¸å½•åˆ¶åŒæ­¥
      startTimelineAnimation(audioElement);
      
      // å¼€å§‹å£å‹åŒæ­¥
      syncVisemeWithAudio(audioElement);
      
    } catch (error) {
      console.error('âŒ Failed to start recording:', error);
      isRecording.value = false;
      
      // æ¸…ç†å¯èƒ½åˆ›å»ºçš„èµ„æº
      if (mediaRecorder.value) {
        mediaRecorder.value.stop();
        mediaRecorder.value = null;
      }
      throw error;
    }
  }

  // åœæ­¢å½•åˆ¶
  function stopRecording() {
    console.log('ğŸ›‘ Stopping recording...');
    
    // é‡ç½®å½•åˆ¶çŠ¶æ€
    isRecording.value = false;
    
    if (mediaRecorder.value) {
      try {
        // å¦‚æœå½•åˆ¶å™¨è¿˜åœ¨è¿è¡Œï¼Œåœæ­¢å®ƒ
        if (mediaRecorder.value.state === 'recording') {
          mediaRecorder.value.stop();
        }
        
        // åœæ­¢æ‰€æœ‰è½¨é“
        if (mediaRecorder.value.stream) {
          mediaRecorder.value.stream.getTracks().forEach((track: MediaStreamTrack) => {
            track.stop();
            console.log('ğŸ›‘ Stopped track:', track.kind);
          });
        }
        
        // æ¸…ç†å½•åˆ¶å™¨
        mediaRecorder.value = null;
      } catch (error) {
        console.error('âŒ Error stopping MediaRecorder:', error);
      }
    }
    
    console.log('âœ… Recording stopped and cleaned up');
  }

  // é‡ç½®å½•åˆ¶çŠ¶æ€
  function resetRecordingState() {
    console.log('ğŸ”„ Resetting recording state...');
    
    // åœæ­¢å½•åˆ¶
    if (isRecording.value) {
      stopRecording();
    }
    
    // æ¸…ç†å½•åˆ¶çš„è§†é¢‘
    if (recordedVideoUrl.value) {
      URL.revokeObjectURL(recordedVideoUrl.value);
      recordedVideoUrl.value = '';
    }
    
    // æ¸…ç†å½•åˆ¶æ•°æ®
    recordedChunks.value = [];
    
    // æ¸…ç†éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (currentAudioContext && currentAudioSource) {
      console.log('ğŸ§¹ Cleaning up audio context and source');
      try {
        currentAudioSource.disconnect();
        currentAudioContext.close();
      } catch (error) {
        console.warn('âš ï¸ Error cleaning up audio context:', error);
      }
      currentAudioContext = null;
      currentAudioSource = null;
      connectedAudioElement = null;
    }
    
    // é‡ç½®çŠ¶æ€
    isRecording.value = false;
    mediaRecorder.value = null;
    
    console.log('âœ… Recording state reset');
  }

  // æ£€æŸ¥å½•åˆ¶çŠ¶æ€
  function checkRecordingState() {
    console.log('ğŸ” Recording state check:', {
      isRecording: isRecording.value,
      mediaRecorder: mediaRecorder.value ? {
        state: mediaRecorder.value.state,
        hasStream: !!mediaRecorder.value.stream
      } : null,
      recordedChunks: recordedChunks.value.length,
      recordedVideoUrl: !!recordedVideoUrl.value
    });
  }

  // ä¸‹è½½è§†é¢‘
  function downloadVideo() {
    if (!recordedVideoUrl.value) {
      throw new Error('No video to download');
    }

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `avatar-animation-${timestamp}.${currentFileExtension}`;
    
    const a = document.createElement('a');
    a.href = recordedVideoUrl.value;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    
    console.log(`ğŸ“¥ Downloaded video as: ${filename}`);
  }

  return {
    isRecording,
    mediaRecorder,
    recordedChunks,
    recordedVideoUrl,
    startRecording,
    stopRecording,
    resetRecordingState,
    checkRecordingState,
    downloadVideo
  };
}
